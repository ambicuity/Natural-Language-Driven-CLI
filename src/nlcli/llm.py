"""
Local LLM integration for Natural Language CLI.
Provides basic foundation for local language model integration.
"""

import logging
from dataclasses import dataclass
from typing import Any, Dict, List, Optional


@dataclass
class LLMConfig:
    """Configuration for LLM integration."""

    model_path: Optional[str] = None
    model_type: str = "huggingface"  # huggingface, ollama, etc.
    max_tokens: int = 512
    temperature: float = 0.1
    enabled: bool = False


@dataclass
class LLMResponse:
    """Response from LLM."""

    text: str
    confidence: float = 0.0
    tokens_used: int = 0
    success: bool = True
    error: Optional[str] = None


class LocalLLM:
    """Local LLM integration for enhanced natural language understanding."""

    def __init__(self, config: LLMConfig):
        self.config = config
        self.model = None
        self.tokenizer = None
        self.logger = logging.getLogger(__name__)

        if config.enabled:
            self._initialize_model()

    def _initialize_model(self) -> bool:
        """Initialize the local LLM model."""
        try:
            if self.config.model_type == "huggingface":
                return self._initialize_huggingface()
            elif self.config.model_type == "ollama":
                return self._initialize_ollama()
            else:
                self.logger.warning(f"Unsupported model type: {self.config.model_type}")
                return False
        except Exception as e:
            self.logger.error(f"Failed to initialize LLM: {e}")
            return False

    def _initialize_huggingface(self) -> bool:
        """Initialize HuggingFace model."""
        try:
            # This would require transformers to be installed
            # For now, just log that it would be initialized
            self.logger.info("HuggingFace model initialization placeholder")
            return True
        except ImportError:
            self.logger.warning("transformers library not available")
            return False

    def _initialize_ollama(self) -> bool:
        """Initialize Ollama model."""
        try:
            # This would require ollama client to be installed
            self.logger.info("Ollama model initialization placeholder")
            return True
        except ImportError:
            self.logger.warning("ollama library not available")
            return False

    def is_available(self) -> bool:
        """Check if LLM is available and ready."""
        return self.config.enabled and self.model is not None

    def enhance_intent_understanding(
        self, user_input: str, context: Dict[str, Any]
    ) -> LLMResponse:
        """
        Use LLM to enhance understanding of user intent.

        Args:
            user_input: Natural language input from user
            context: Current session context

        Returns:
            Enhanced understanding or clarification
        """
        if not self.is_available():
            # Try cloud LLM fallback
            return self._try_cloud_fallback(user_input, context, "intent")

        # Placeholder for actual LLM processing
        # This would send the input through the model for enhanced understanding
        prompt = self._build_intent_prompt(user_input, context)

        # For now, just return the original input
        return LLMResponse(text=user_input, confidence=0.5, success=True)

    def suggest_tool_selection(
        self, user_input: str, available_tools: List[str]
    ) -> LLMResponse:
        """
        Use LLM to suggest the best tool for the user input.

        Args:
            user_input: Natural language input from user
            available_tools: List of available tool names

        Returns:
            Tool suggestion with confidence
        """
        if not self.is_available():
            # Try cloud LLM fallback
            return self._try_cloud_fallback(
                user_input, {"tools": available_tools}, "tool_selection"
            )

        # Placeholder for actual LLM processing
        prompt = self._build_tool_selection_prompt(user_input, available_tools)

        # Simple heuristic fallback
        for tool in available_tools:
            if any(keyword in user_input.lower() for keyword in tool.split("_")):
                return LLMResponse(text=tool, confidence=0.6, success=True)

        return LLMResponse(
            text=available_tools[0] if available_tools else "",
            confidence=0.1,
            success=True,
        )

    def _try_cloud_fallback(
        self, user_input: str, context: Dict[str, Any], task_type: str
    ) -> LLMResponse:
        """Try cloud LLM as fallback when local LLM is not available."""
        try:
            from nlcli.cloud_llm import get_cloud_llm_service

            cloud_llm = get_cloud_llm_service()

            if not cloud_llm.is_available():
                return LLMResponse(
                    text=user_input,
                    success=False,
                    error="Neither local nor cloud LLM available",
                )

            # Build appropriate prompt based on task type
            if task_type == "intent":
                system_prompt = self._build_intent_system_prompt()
                prompt = (
                    f"Analyze this user request and extract the intent: '{user_input}'"
                )
            elif task_type == "tool_selection":
                system_prompt = self._build_tool_selection_system_prompt()
                tools_list = "\n".join(f"- {tool}" for tool in context.get("tools", []))
                prompt = f"Given these available tools:\n{tools_list}\n\nWhich tool is best for: '{user_input}'"
            elif task_type == "explanation":
                system_prompt = "You are a helpful assistant that explains command-line operations clearly and concisely."
                prompt = f"Explain what this command does: {user_input}"
            else:
                system_prompt = (
                    "You are a helpful assistant for command-line operations."
                )
                prompt = user_input

            cloud_response = cloud_llm.generate_response(prompt, system_prompt)

            if cloud_response.success:
                self.logger.info(
                    f"Cloud LLM fallback successful with {cloud_response.provider}"
                )
                return LLMResponse(
                    text=cloud_response.text,
                    confidence=cloud_response.confidence,
                    tokens_used=cloud_response.tokens_used,
                    success=True,
                )
            else:
                self.logger.warning(
                    f"Cloud LLM fallback failed: {cloud_response.error}"
                )
                return LLMResponse(
                    text=user_input,
                    success=False,
                    error=f"Cloud LLM fallback failed: {cloud_response.error}",
                )

        except ImportError:
            return LLMResponse(
                text=user_input, success=False, error="Cloud LLM support not available"
            )
        except Exception as e:
            self.logger.error(f"Cloud LLM fallback error: {e}")
            return LLMResponse(
                text=user_input, success=False, error=f"Cloud LLM fallback error: {e}"
            )

    def _build_intent_system_prompt(self) -> str:
        """Build system prompt for intent understanding."""
        return """You are an expert at understanding natural language commands for system administration and file operations.
Your job is to analyze user requests and extract the key intent, parameters, and context.

Focus on identifying:
- The main action (show, list, find, delete, copy, etc.)
- Target objects (files, processes, directories, etc.)
- Filters and conditions (size, date, permissions, etc.)
- Location context (directories, paths)

Return clear, structured analysis of the user's intent."""

    def _build_tool_selection_system_prompt(self) -> str:
        """Build system prompt for tool selection."""
        return """You are an expert at selecting the best command-line tool for user requests.
Given a list of available tools and a user request, select the most appropriate tool.

Consider:
- The type of operation requested
- The objects being operated on
- The best tool for the specific use case

Return only the tool name that best matches the request."""

    def suggest_tool_selection(
        self, user_input: str, available_tools: List[str]
    ) -> LLMResponse:
        """
        Use LLM to suggest the best tool for user input.

        Args:
            user_input: Natural language input
            available_tools: List of available tool names

        Returns:
            Suggested tool and reasoning
        """
        if not self.is_available():
            return LLMResponse(text="", success=False, error="LLM not available")

        prompt = self._build_tool_selection_prompt(user_input, available_tools)

        # Placeholder for actual LLM processing
        return LLMResponse(text="", confidence=0.5, success=True)

    def explain_command(self, command: str, context: Dict[str, Any]) -> str:
        """
        Generate natural language explanation for a command.

        Args:
            command: Shell command to explain
            context: Current context

        Returns:
            Natural language explanation
        """
        if self.is_available():
            # Try local LLM first (placeholder implementation)
            explanation = f"Will execute: {command}"
        else:
            # Try cloud fallback
            llm_response = self._try_cloud_fallback(command, context, "explanation")
            if llm_response.success:
                return llm_response.text
            explanation = f"Will execute: {command}"

        # Add context-aware enhancements
        if "rm" in command and "-rf" in command:
            explanation += " âš ï¸  This is a destructive operation that will permanently delete files."
        elif "sudo" in command:
            explanation += " âš ï¸  This command requires administrator privileges."
        elif command.startswith("find"):
            explanation += " ðŸ” This searches for files and directories."
        elif command.startswith(("ls", "ll")):
            explanation += " ðŸ“ This lists directory contents."

        return explanation

    def _build_intent_prompt(self, user_input: str, context: Dict[str, Any]) -> str:
        """Build prompt for intent understanding."""
        return f"""
Analyze this user request and clarify the intent:

User input: "{user_input}"
Context: {context}

Provide a clear interpretation of what the user wants to accomplish.
"""

    def _build_tool_selection_prompt(self, user_input: str, tools: List[str]) -> str:
        """Build prompt for tool selection."""
        tools_list = "\n".join(f"- {tool}" for tool in tools)

        return f"""
Given this user request, which tool would be most appropriate?

User input: "{user_input}"

Available tools:
{tools_list}

Select the best tool and explain why.
"""


def create_llm(config: Optional[LLMConfig] = None) -> LocalLLM:
    """Create and return a LocalLLM instance."""
    if config is None:
        config = LLMConfig()

    return LocalLLM(config)


# Default disabled LLM instance for backward compatibility
default_llm = create_llm(LLMConfig(enabled=False))
